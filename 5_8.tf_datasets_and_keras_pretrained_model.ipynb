{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU,Dense, BatchNormalization, Softmax, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "training_epochs = 2\n",
    "batch_size = 32\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow_Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train, validation, test 비율 설정\n",
    "SPLIT_WEIGHTS = (8, 1, 1)\n",
    "## cats vs dogs dataset을 tensorflow_datasets에서 load하고\n",
    "## training dataset을 위에서 설정한 비율대로 나누어서 train, validation, test dataset으로 구성\n",
    "splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load('cats_vs_dogs', split=list(splits),\n",
    "                                                            with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n",
      "<_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n",
      "<_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing 함수\n",
    "@tf.function\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255.\n",
    "    image = tf.image.resize(image, (img_size, img_size))\n",
    "    label = tf.one_hot(label, 2)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprecessing 함수를 dataset에 적용\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "[0. 1.]\n",
      "(224, 224, 3)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "## image와 label 확인\n",
    "for images, labels in train.take(2):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 및 shuffle 적용\n",
    "train_dataset = train.shuffle(1000).batch(batch_size).repeat()\n",
    "val_dataset = validation.batch(batch_size)\n",
    "test_dataset = test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "## batch size 반영되어 있는지 확인\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pretrained model load\n",
    "conv_base = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                       input_shape=(img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dense layer 추가하여 network 구성\n",
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Dense(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Softmax())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,422,730\n",
      "Trainable params: 2,388,358\n",
      "Non-trainable params: 34,372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18609.6 2326.2 2326.2\n"
     ]
    }
   ],
   "source": [
    "## Training, Validation, Test data 수 확인\n",
    "num_train, num_val, num_test = (\n",
    "  metadata.splits['train'].num_examples*weight/10\n",
    "  for weight in SPLIT_WEIGHTS\n",
    ")\n",
    "print(num_train, num_val, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 72\n"
     ]
    }
   ],
   "source": [
    "## steps_per_epoch, validation_steps 계산\n",
    "steps_per_epoch = round(num_train)//batch_size\n",
    "validation_steps = round(num_val)//batch_size\n",
    "print(steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 3:01 - loss: 0.8880 - accuracy: 0.31 - ETA: 1:00 - loss: 0.8400 - accuracy: 0.41 - ETA: 36s - loss: 0.8123 - accuracy: 0.4563 - ETA: 26s - loss: 0.7949 - accuracy: 0.482 - ETA: 20s - loss: 0.7865 - accuracy: 0.493 - ETA: 16s - loss: 0.7638 - accuracy: 0.511 - ETA: 15s - loss: 0.7752 - accuracy: 0.510 - ETA: 12s - loss: 0.7781 - accuracy: 0.513 - ETA: 11s - loss: 0.7896 - accuracy: 0.502 - ETA: 10s - loss: 0.7910 - accuracy: 0.498 - ETA: 9s - loss: 0.7894 - accuracy: 0.501 - ETA: 8s - loss: 0.7928 - accuracy: 0.49 - ETA: 7s - loss: 0.7892 - accuracy: 0.50 - ETA: 7s - loss: 0.7877 - accuracy: 0.50 - ETA: 6s - loss: 0.7866 - accuracy: 0.50 - ETA: 5s - loss: 0.7894 - accuracy: 0.50 - ETA: 5s - loss: 0.7894 - accuracy: 0.50 - ETA: 5s - loss: 0.7903 - accuracy: 0.50 - ETA: 4s - loss: 0.7915 - accuracy: 0.49 - ETA: 4s - loss: 0.7952 - accuracy: 0.49 - ETA: 4s - loss: 0.7898 - accuracy: 0.50 - ETA: 3s - loss: 0.7887 - accuracy: 0.50 - ETA: 3s - loss: 0.7886 - accuracy: 0.50 - ETA: 3s - loss: 0.7920 - accuracy: 0.49 - ETA: 2s - loss: 0.7990 - accuracy: 0.49 - ETA: 2s - loss: 0.7975 - accuracy: 0.49 - ETA: 2s - loss: 0.8035 - accuracy: 0.49 - ETA: 2s - loss: 0.8022 - accuracy: 0.49 - ETA: 1s - loss: 0.8038 - accuracy: 0.49 - ETA: 1s - loss: 0.8060 - accuracy: 0.49 - ETA: 1s - loss: 0.8068 - accuracy: 0.49 - ETA: 1s - loss: 0.8131 - accuracy: 0.48 - ETA: 1s - loss: 0.8106 - accuracy: 0.48 - ETA: 1s - loss: 0.8116 - accuracy: 0.48 - ETA: 0s - loss: 0.8107 - accuracy: 0.49 - ETA: 0s - loss: 0.8114 - accuracy: 0.49 - ETA: 0s - loss: 0.8135 - accuracy: 0.49 - ETA: 0s - loss: 0.8106 - accuracy: 0.49 - ETA: 0s - loss: 0.8129 - accuracy: 0.49 - ETA: 0s - loss: 0.8140 - accuracy: 0.49 - 6s 80ms/step - loss: 0.8154 - accuracy: 0.4913\n"
     ]
    }
   ],
   "source": [
    "## initial loss & accuracy 계산\n",
    "loss0, accuracy0 = model.evaluate(val_dataset, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 0.82\n",
      "initial accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 01:18:09.136595 25636 deprecation.py:323] From c:\\users\\jwlee\\anaconda3\\envs\\tf2_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 - 182s - loss: 0.1761 - accuracy: 0.9732 - val_loss: 0.1122 - val_accuracy: 0.9831\n",
      "Epoch 2/2\n",
      "581/581 - 159s - loss: 0.1339 - accuracy: 0.9912 - val_loss: 0.1080 - val_accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=training_epochs,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data=val_dataset,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
