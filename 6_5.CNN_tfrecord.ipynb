{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i031PQnUh2sn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7d7VyGjh2sq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, Softmax, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhSyxzZSh2ss"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ggSD16Wkh2su"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "img_size = 150\n",
    "batch_size = 16\n",
    "training_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBrUS_MOh2sw"
   },
   "outputs": [],
   "source": [
    "n_train = 7488\n",
    "n_val = 2496\n",
    "n_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OT-3IY1iiA84"
   },
   "outputs": [],
   "source": [
    "cd '/content/gdrive/My Drive/TensorFlow_Training_13th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZMkVM0rh2sy"
   },
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "\n",
    "tfrecord_dir = os.path.join(cur_dir, 'tfrecords')\n",
    "tfrecord_train = 'simpsons_train.tfrecord'\n",
    "tfrecord_val = 'simpsons_val.tfrecord'\n",
    "\n",
    "train_tfr_dir = os.path.join(tfrecord_dir, tfrecord_train)\n",
    "val_tfr_dir = os.path.join(tfrecord_dir, tfrecord_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FuBxDInWh2s0"
   },
   "outputs": [],
   "source": [
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
    "             'label': tf.io.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [img_size, img_size, 3])\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    \n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    label = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgEtrCPxh2s2"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfr_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=n_train*2).prefetch(\n",
    "    buffer_size=batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzTkhI-ih2s4"
   },
   "outputs": [],
   "source": [
    "val_dataset = tf.data.TFRecordDataset(val_tfr_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh2N73lPh2s7"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Conv2D(32, 3, input_shape=(img_size, img_size, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(64, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(256, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(512, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(512, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(n_class))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Softmax())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8a7HZK6h2s_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss_fn(model, images, labels):\n",
    "    predictions = model(images, training=True)\n",
    "    loss = tf.reduce_mean(keras.losses.categorical_crossentropy(labels, predictions))   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTaLqjZ7h2tB"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWdZZCrmh2tD"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluate(model, images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtJpcswJh2tG"
   },
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=n_train//batch_size*10,\n",
    "                                                          decay_rate=0.5,\n",
    "                                                          staircase=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2sRxIvPh2tI"
   },
   "outputs": [],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_val_acc = 0.\n",
    "    train_step = 0\n",
    "    val_step = 0\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        train(model,images, labels)\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_loss = avg_loss + loss\n",
    "        avg_train_acc = avg_train_acc + acc\n",
    "        train_step += 1        \n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in val_dataset:\n",
    "        acc = evaluate(model, images, labels)        \n",
    "        avg_val_acc = avg_val_acc + acc\n",
    "        val_step += 1    \n",
    "    avg_val_acc = avg_val_acc / val_step    \n",
    "\n",
    "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
    "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
    "          'validation accuracy = ', '{:.4f}'.format(avg_val_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TZwwgHXiMgQ"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(cur_dir, 'simpsons_train')\n",
    "class_names = sorted([dname for dname in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, dname))])\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img[:,:,:])\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    #plt.xticks([])\n",
    "    plt.xticks(range(n_class), class_names, rotation=90)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(n_class), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23p7hVepiNDA"
   },
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(1, n_val//batch_size)\n",
    "img_cnt = 0\n",
    "for images, labels in val_dataset:\n",
    "    img_cnt += 1\n",
    "    if img_cnt != rnd_idx:\n",
    "        continue\n",
    "    predictions = model(images, training=False)\n",
    "    num_rows = 5\n",
    "    num_cols = 3\n",
    "    num_images = num_rows*num_cols\n",
    "    labels = tf.argmax(labels, axis=-1)\n",
    "    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n",
    "    plt.subplots_adjust(hspace=1.0)\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4OV1CBth2tK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "read_tfrecord_cnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
