{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pima Indians Diabetes Dataset for Binary Classification\n",
    "\n",
    "This dataset describes the medical records for Pima Indians and whether or not each patient will have an onset of diabetes within five years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can be downloaded from https://www.kaggle.com/kumargh/pimaindiansdiabetescsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 dataset의 몇가지 주요 항목을 살펴보면 다음과 같습니다\n",
    "\n",
    "- 인스턴스 수 : 768개\n",
    "- 속성 수 : 8가지\n",
    "- 클래스 수 : 2가지\n",
    "\n",
    "8가지 속성(1번~8번)과 결과(9번)의 상세 내용은 다음과 같습니다.\n",
    "\n",
    "1. 임신 횟수\n",
    "2. 경구 포도당 내성 검사에서 2시간 동안의 혈장 포도당 농도\n",
    "3. 이완기 혈압 (mm Hg)\n",
    "4. 삼두근 피부 두겹 두께 (mm)\n",
    "5. 2 시간 혈청 인슐린 (mu U/ml)\n",
    "6. 체질량 지수\n",
    "7. 당뇨 직계 가족력\n",
    "8. 나이 (세)\n",
    "9. 5년 이내 당뇨병이 발병 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_FILE = './data/pima-indians-diabetes.csv'\n",
    "#DATA_FILE = '/content/gdrive/My Drive/TensorFlow_Training_13th/data/pima-indians-diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt(DATA_FILE, delimiter=',', dtype=np.float32)\n",
    "x_train = xy[:, 0:-1]\n",
    "y_train = xy[:, [-1]]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    ''' Min Max Normalization\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        input data to be normalized\n",
    "        shape: [Batch size, dimension]\n",
    "    Returns\n",
    "    ----------\n",
    "    data : numpy.ndarry\n",
    "        normalized data\n",
    "        shape: [Batch size, dimension]\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "    '''\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = MinMaxScaler(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = x_train.shape[0]\n",
    "n_epoch = 1000\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal_initializer()([8, 1]))\n",
    "b = tf.Variable(tf.random_normal_initializer()([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(inputs):\n",
    "    hypothesis = tf.keras.activations.sigmoid(tf.matmul(inputs, w) + b)\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(inputs, labels):\n",
    "    hypothesis = logistic_regression(inputs)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, hypothesis))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(inputs, labels):\n",
    "    hypothesis = logistic_regression(inputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(inputs, labels)\n",
    "    grads = tape.gradient(loss, [w, b])\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(inputs, labels):\n",
    "    hypothesis = logistic_regression(inputs)\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, labels), dtype=tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_steps = int(x_train.shape[0]/batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    total_loss = 0.\n",
    "    for x, y in dataset: \n",
    "        grads = grad(x, y)        \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))\n",
    "        loss = loss_fn(x, y)\n",
    "        total_loss += loss / total_steps\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch {0}: {1:.8f}'.format(epoch+1, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(accuracy_fn(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
